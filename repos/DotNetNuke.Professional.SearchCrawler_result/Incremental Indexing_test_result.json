{
  "metadata": {
    "extension_name": "DotNetNuke.Professional.SearchCrawler",
    "extension_type": "Module",
    "feature_name": "Incremental Indexing",
    "feature_description": "Indexes only changed content since last crawl to improve performance.",
    "feature_priority": "Medium",
    "test_date": "2026-01-16T13:46:00Z",
    "tester": "Claude"
  },
  "test_scenarios": [
    {
      "scenario_name": "Track last crawl date",
      "status": "PASS",
      "steps": [
        {
          "step_number": 1,
          "action": "Navigate to Scheduler panel and locate Search: File Crawler task",
          "expected": "Task should be visible in scheduler with task history available",
          "actual": "Search: File Crawler task found with frequency of Every 1 Day and enabled status",
          "screenshot": "Incremental_Indexing_step02_scheduler_tab.png"
        },
        {
          "step_number": 2,
          "action": "View Task History for Search: File Crawler",
          "expected": "History should show 'Scanning for files changed since: [date]' indicating last crawl tracking",
          "actual": "Task History shows 'Scanning for files changed since: 1/16/2026 1:16 PM' confirming last crawl date is tracked",
          "screenshot": "Incremental_Indexing_step03_task_history.png"
        }
      ],
      "issues": []
    },
    {
      "scenario_name": "Identify changed files",
      "status": "PASS",
      "steps": [
        {
          "step_number": 1,
          "action": "Examine Task History logs for file change detection",
          "expected": "Logs should show count of new or changed files since last crawl",
          "actual": "Logs show 'Number of new or changed files since last crawl: 48' indicating the system correctly identifies changed files",
          "screenshot": "Incremental_Indexing_step03_task_history.png"
        },
        {
          "step_number": 2,
          "action": "Verify File Crawler Results breakdown",
          "expected": "Results should include counts for files encountered, changed, shallow indexed, and deep indexed",
          "actual": "Results show: 135 files encountered, 48 new/changed files, 47 shallow indexed, 1 deep indexed, 1 failed deep index",
          "screenshot": "Incremental_Indexing_step03_task_history.png"
        }
      ],
      "issues": []
    },
    {
      "scenario_name": "Skip unchanged files",
      "status": "PASS",
      "steps": [
        {
          "step_number": 1,
          "action": "Review multiple Task History entries for runs where no files changed",
          "expected": "When no files have changed since last crawl, the system should report 0 changed files and 0 indexed",
          "actual": "Multiple history entries (1/16/2026 1:16 PM, 1/15/2026 3:56 PM, 1/14/2026 3:26 PM) show 'Number of new or changed files since last crawl: 0' with all index counts at 0, confirming unchanged files are skipped",
          "screenshot": "Incremental_Indexing_step04_skip_unchanged.png"
        },
        {
          "step_number": 2,
          "action": "Compare crawl duration between runs with changed vs unchanged files",
          "expected": "Runs with no changes should complete faster",
          "actual": "Run with 0 changed files completed in 0.297 seconds vs 0.977 seconds for run with 48 changed files, demonstrating performance improvement",
          "screenshot": "Incremental_Indexing_step03_task_history.png"
        }
      ],
      "issues": []
    },
    {
      "scenario_name": "Verify SHA1 hash comparison",
      "status": "PASS",
      "steps": [
        {
          "step_number": 1,
          "action": "Review FileCrawlerController.cs code for SHA1 hash implementation",
          "expected": "Code should show SHA1 hash being stored and used for file comparison",
          "actual": "Code review confirmed: IndexedFile class (line 380) stores Sha1Hash property. The CreateIndexedFile method stores the file's SHA1Hash for comparison during subsequent crawls",
          "screenshot": "Incremental_Indexing_step05_task_settings.png"
        }
      ],
      "issues": ["SHA1 hash comparison is implemented in code but not directly visible in UI task history logs"]
    },
    {
      "scenario_name": "Test modification date detection",
      "status": "PASS",
      "steps": [
        {
          "step_number": 1,
          "action": "Verify modification date comparison in Task History",
          "expected": "System should compare file modification dates against last crawl date",
          "actual": "Task History shows 'Scanning for files changed since: [date]' for each run. Code review confirmed RemoveFilesUnchangedSinceLastRun method (line 306) compares fileInfo.LastModifiedOnDate against lastIndexDate",
          "screenshot": "Incremental_Indexing_step03_task_history.png"
        },
        {
          "step_number": 2,
          "action": "Observe incremental behavior when files are modified",
          "expected": "Only files modified after the last crawl date should be re-indexed",
          "actual": "History entry from 1/13/2026 shows 8 changed files after a 4-day gap, while subsequent daily runs show 0 changed files when no modifications occurred",
          "screenshot": "Incremental_Indexing_step03_task_history.png"
        }
      ],
      "issues": []
    }
  ],
  "observations": [
    "SHA1 hash comparison is implemented in FileCrawlerController.cs but hash values are not displayed in the UI task history logs - only file counts are shown",
    "Clock skew handling is implemented in code (line 299: lastIndexDate calculation considers timing between lastIndexedFileModificationDate and LastScheduledRunStartTime) but cannot be practically tested via UI without specific system configuration",
    "The File Crawler task runs daily by default (Every 1 Day) which is appropriate for incremental indexing of files",
    "iFilter errors for specific documents (docx, pdf) are logged but do not prevent the crawler from continuing with other files",
    "The system maintains a persistent record of previously indexed files to enable accurate incremental comparisons"
  ],
  "summary": {
    "total_scenarios": 5,
    "passed": 5,
    "failed": 0,
    "pass_rate": "100%"
  }
}
